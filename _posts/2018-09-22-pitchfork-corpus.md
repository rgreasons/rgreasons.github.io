---
layout: post
title: Pitchfork's Shifting Corpus in 5 Charts 
tags: music pitchfork
---

As outlined in my [previous](http://www.rgreasons.net/2016/06/25/Scraping.html) [posts](http://www.rgreasons.net/2018/09/09/Scraping-Revisited.html), I went through the trouble of scraping over 15 years of one of the leading independent music websites. Pitchfork shaped my record collection over the past 10 years I have been reading the publication, but nowadays it feels like a totally different website. I wanted to take a look and see if there was any evidence that supported my intuition.

<!--excerpt-->

Before I get too into the weeds, I want to call attention to four events in recent Pitchfork history that I expected to be inflection points in the site's direction. The first three events are turning points in how Pitchfork conducted its business and its reviews and the last was (what I suspected) a turning point in the site's critical focus.


1. Publishing conglomerate Conde Nast [acquires](https://pitchfork.com/news/61621-pitchfork-acquired-by-conde-nast/) Pitchfork on October 13, 2015. The acquisition was, to my knowledge, the first time the website became beholden to outside financing.
2. Pitchfork deviates from its "5 reviews, 5 days a week" schedule to start publishing reviews on Saturday starting in April of 2016. The website [cites](https://pitchfork.com/news/64915-pitchfork-to-publish-album-reviews-on-saturdays/) the move of album release dates to Friday, but I suspect the move also served to smooth out the website's traffic across the entire week.
3. The [Sunday Review](https://pitchfork.com/news/65994-pitchfork-presents-the-sunday-review/) is introduced on June 9 2016, a chance for Pitchfork to review albums that it had not been able to review at the time of their original releases. 
4. The perfect score given to Kanye West's *My Beautiful Dark Twisted Fantasy* on [November 22, 2010](https://pitchfork.com/reviews/albums/14880-my-beautiful-dark-twisted-fantasy/). It was the first perfect score the site granted to a newly-released album in eight years and serves as an acknowledgement of hip hop's cultural importance even on a historically rockist publication.

I first wanted to see how consistent the site has been in sticking to its publishing schedule.

![alt text](/img/pitchfork1-1.png "Pitchfork Reviews By Year")

The chart shows that the site has been surprisingly consistent over the past 10 years. Some of this fluctuation is partially due to my methodology - I count reviews in which multiple reissues are analyzed in one editorial (such as [this review of Lifter Puller reissues](https://pitchfork.com/reviews/albums/13744-lifter-puller-half-dead-and-dynamite-the-entertainment-and-arts-ep-fiestas-and-fiascos-slips-backwards/)) as multiple reviews.

I suspect there's a confluence of factors as to why there are so many fewer reviews prior to 2002.  One, there's a good chance the site finally picked up enough after the turn of the millennium to pivot from Ryan Schrieber's passion project to a full-blown publication. Two, the site has changed content management systems since it was first created and it's likely some reviews got lost along the way. Third, there is evidence (via cross-referencing with archive.org) that Pitchfork has removed some of its most controversial reviews and I expect their older reviews are more likely to be irreverent and inconsistent than newer reviews.

It's also worth noting that the site appears to have doubled down on its review efforts since its acquisition by Conde Nast. The increase in the number of reviews in 2016 is larger than the 50 or so Sunday reviews that wouldn't have been present in previous years.  Although the the move to post reviews on Saturdays was billed as just a shift in publishing patterns, it seems to have led to more reviews overall.

Even though the site publicized its publishing shifts in 2015, I believe they had experienced an unpublicized editorial shift years earlier. The emergence of [poptimism](https://en.wikipedia.org/wiki/Rockism_and_poptimism) and the economics of web publishing in the 2010s forced the site to pivot its focus away from the independent rock records that propelled the site to prominence.

The below chart shows the percentage of reviews in a year that were associated with a given genre.

![alt text](/img/Pitchfork1-2.png "Pitchfork Review Genre Percentage by Year")

The above chart bears out my hypothesis, but I'd like to point out some notes that I had not anticipated at all.

* Jazz reviews have actually increased in the past few years. I don't associate Pitchfork with any jazz other than Thundercat, Kamasi Washington, and reissues of Coltrane and Blue Note records. Maybe the jazz reissue scene is thriving?
* Folk/Country reviews hit a nadir around 2012 even though that's the timespan I most associate with the California folk-rock resurgence. My guess is that, for whatever reason, releases in the Father John Misty/Fleet Foxes/Devendra Banhart mold were treated as rock releases.
* Electronic reviews have stayed fairly constant throughout the site's history. I expected a bigger dip in the mid-2000s, but that's probably more of a personal blindspot of that time period than a reflection of the site's coverage. The big uptick in electronic reviews around 2010 makes perfect sense to me. The site felt like the epicenter of all sorts of polarizing genres such as [witch house](https://en.wikipedia.org/wiki/Witch_house_(genre)) and [chillwave](https://en.wikipedia.org/wiki/Chillwave).

My biggest takeaway from the above chart, however, was how Pop and Rap coverage has begun to slowly replace the site's rock reviews.

![alt text](/img/Pitchfork1-3.png "Change in Pitchfork Reviews of Rock, Rap, and Pop Albums over Time")

I had anticipated this before I had even looked at the chart. The aforementioned Kanye review was a huge indicator to me, as were glowing reviews of Future and Kendrick Lamar records. But the site's coverage of Drake, which included [multiple](https://pitchfork.com/news/54903-drake-caught-lint-rolling-pants-courtside-at-raptorsnets-playoff-game/) [stories](https://pitchfork.com/news/55008-toronto-raptors-hand-out-drake-branded-lint-rollers/) detailing his association with lint rollers, drove home the site's dedication to rap and hip hop. I was surprised that this mainstream coverage was muscling out rock reviews instead of the occasional Jazz or Global music review.

Pitchfork is also well-known for using the entirety of its 10-point review scale. Many publications treat a 10-point scale in the same was as the American school system’s letter grades - 90 or above is an A, 75 is a C, and anything 6 is below is a failing grade. Pitchfork was not afraid to dip below 5 if the writer and editorial board did not like a record and didn’t shy away from truly abysmal grades and kicking a band while it was down.  The below chart shows how often Pitchfork has “panned” (granted a score of 5 or lower) a record as well as how often they have “ravaged” (2.5 or lower, my terminology) a record.

![alt text](/img/Pitchfork1-4.png "Frequency of Sever Pitchfork Reviews over Time")

I think it’s really interesting that, although these negative reviews led to the site’s infamy, they backed away from such coverage when they started to gain mainstream success.  In the span of two years, from 2008 to 2010, they halved the number of records that they gave really negative grades.

The practice of totally eviscerating a review appears to be dead. One of my favorite writers, [Ian Cohen](https://twitter.com/@en_cohen), served up the last one of these reviews in 2016 when he covered an [EP by rap-rock supergroup Prophets of Rage](https://pitchfork.com/reviews/albums/22319-the-partys-over-ep/). 2017 was the only year that I analyzed that did not have a review that met this threshold, although [this Ed Sheeran review](https://pitchfork.com/reviews/albums/22960-divide/) makes me wonder if I should have raised my cutoff a few fractions of a point. Even when they want to be truly scathing, the scores given to albums seem to be reverting to the mean.

Lastly, I wanted to look and see if the change in review severity had an outsized effect on the coverage of any particular genre. I expected each one of these charts to trend downward, following the overall trend toward less severe scores, but with this even slightly increased percentages on this chart indicate a much more critical staff.

![alt text](/img/Pitchfork1-5.png "Percentage of Reviews Panned per Genre by Year")

Some Takeaways:
* It looks like early-2000s Pop and late-2000s rap were the two time periods that found themselves in the crosshairs most often. 
* Heavy music (which usually gets lumped into “Metal” regardless of sub-genre) appears to be the target of negative opinions consistently more often than other genres over the years. Despite bringing in great writers such as [Kim Kelly](https://twitter.com/@GrimKim) to [do the genres more justice](https://pitchfork.com/staff/kim-kelly/albumreviews/), it doesn’t appear the overall editorial needle shifted too much. 
* I was honestly surprised to see any Global music pans, since I don’t associate Pitchfork with world music whatsoever. But since they consider [Matisyahu](https://pitchfork.com/reviews/albums/9747-no-place-to-be/) “Global,” I guess it makes sense.

Although this is just a broad overview of the body of reviews at Pitchfork, I feel it confirms my hunches that the publication’s genre focus and hyper-critical voice have shifted since I began reading it years ago.

I have some other ideas of things to investigate using this data in the near future, but don’t hesitate to reach out if you have a burning question that you think I may be able to quantify. For any other data folks reading this, I have included the R Markdown notebook I used to create the charts in [the project’s GitHub repository](https://github.com/rgreasons/pytch) and plan to post a write-up on my experiences wrestling with plotting libraries in R and Python in the coming weeks.